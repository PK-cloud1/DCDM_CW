import re
import pandas as pd
import numpy as np
import warnings

# --- File Paths (Matching User Input) ---
input_file = "/scratch/grp/msc_appbio/DCDM/Group11/data/IMPC_procedure.csv"
output_file = "/scratch/grp/msc_appbio/DCDM/Group11/data/mt_IMPC_procedure_cleaned.csv"

# --- Output Headers (Matching R script output structure: 4 columns) ---
# The R script separates 'name' (first field) and 'description' (middle fields).
OUTPUT_HEADERS = ["name", "description", "isMandatory", "impcParameterOrigId"]

def is_numeric_like(token: str) -> bool:
    """Checks if a string token consists only of digits."""
    return bool(re.match(r"^\d+$", token.strip()))

def clean_and_normalize_impc_csv(input_path: str, output_path: str) -> pd.DataFrame:
    """
    Cleans the IMPC procedure CSV file by robustly parsing lines that contain
    unquoted commas in the description field, mirroring the R script logic.
    """
    print(f"Reading raw data from: {input_path}")

    try:
        # Read the file line by line, skipping the header for manual parsing
        with open(input_path, mode="r", encoding="utf-8") as f:
            raw_lines = f.readlines()
    except FileNotFoundError:
        print(f"Error: Input file not found at {input_path}")
        return pd.DataFrame()
    
    if len(raw_lines) < 2:
        print("Error: Input file is empty or contains only a header.")
        return pd.DataFrame()

    # The R script ignores the header, so we start from the first data row.
    data_lines = raw_lines[1:]
    
    parsed_data = []

    for line in data_lines:
        line = line.strip()
        if not line:
            continue

        # 1. Split by comma (this is the core issue: description contains unquoted commas)
        fields = [f.strip() for f in line.split(",")]
        
        # We need at least 3 parts: name, mandatory, id
        if len(fields) < 3:
            continue

        # --- R Logic: Robustly find impcParameterOrigId from the end ---

        # 2. Find the index of the last numeric-like token (impcParameterOrigId)
        id_index = -1
        for i in range(len(fields) - 1, -1, -1):
            if is_numeric_like(fields[i]):
                id_index = i
                break

        if id_index == -1:
            # Cannot robustly parse the line, skip it
            continue

        # 3. Identify the final tokens based on the found ID index
        impc_id_token = fields[id_index]
        
        # isMandatory is expected to be immediately before the ID
        mandatory_index = id_index - 1
        
        if mandatory_index < 1:
            # Not enough fields remaining for name (index 0) and mandatory (index 1)
            continue
            
        mandatory_token = fields[mandatory_index]
        name_token = fields[0] # Name is always the first token

        # 4. Description components are everything between the name and mandatory fields
        # Note: The R script uses fields[2:(second_last_idx - 1)]
        mid_tokens = fields[1:mandatory_index]
        
        # Join middle tokens with a space and clean up excess whitespace
        description_str = " ".join(mid_tokens).strip()
        description_str = re.sub(r"\s+", " ", description_str)

        # 5. Store the parsed data
        parsed_data.append({
            "name": name_token,
            "description": description_str,
            "isMandatory": mandatory_token,
            "impcParameterOrigId": impc_id_token,
        })

    if not parsed_data:
        print("Error: No valid rows parsed. Input file format may be incompatible.")
        return pd.DataFrame()

    # Create initial DataFrame
    df = pd.DataFrame(parsed_data, columns=OUTPUT_HEADERS)

    # --- R Logic: Data Normalization and Transformation ---
    
    # Normalize isMandatory to boolean (True/False/NA)
    def canonical_boolean(x):
        x = str(x).strip().upper()
        if x in ("TRUE", "T", "1"):
            return True
        elif x in ("FALSE", "F", "0", ""):
            return False
        else:
            return np.nan # Use pandas/numpy NA marker

    df['isMandatory'] = df['isMandatory'].apply(canonical_boolean)

    # Convert ID to numeric
    # Suppress warnings during coercion as in R's suppressWarnings()
    with warnings.catch_warnings():
        warnings.simplefilter("ignore", category=pd.errors.DtypeWarning)
        df['impcParameterOrigId'] = pd.to_numeric(df['impcParameterOrigId'], errors='coerce')
    
    # Remove exact duplicate rows
    df.drop_duplicates(inplace=True)

    # Normalize textual NA/empty strings to Python's NaN (matching R's NA_character_)
    na_values = ["NA", "N/A", ""]
    for col in ["name", "description"]:
        df[col] = df[col].replace(na_values, np.nan, regex=False)
        # Ensure description empty string is also NA after initial parsing
        df[col].replace("", np.nan, inplace=True)
        df[col] = df[col].str.strip() # Final trim
        
    # Sort by ID (matching R's order())
    # R's na.last=TRUE is the default behavior in pandas sort_values
    df.sort_values(by='impcParameterOrigId', ascending=True, na_position='last', inplace=True)
    df.reset_index(drop=True, inplace=True)

    # --- R Logic: Save to CSV ---
    # R's write.table with na="" and quote=TRUE is replicated by:
    # index=False, na_rep="" (replaces NaN with empty string), quoting=csv.QUOTE_ALL (similar to quote=TRUE)
    
    # pandas writes a clean CSV with fields quoted (like R's quote=TRUE)
    df.to_csv(
        output_path, 
        index=False, 
        encoding='utf-8', 
        sep=',', 
        header=True,
        na_rep="" # Write NA as empty string, matching R's na=""
    )
    
    print(f"Cleaning complete. {len(df)} unique rows saved to: {output_path}")
    return df

if __name__ == "__main__":
    clean_and_normalize_impc_csv(input_file, output_file)
